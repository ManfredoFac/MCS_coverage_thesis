{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoLife Augmentation\n",
    "1. Download car, bike, pedestrian maps\n",
    "2. Generate trajectories:\n",
    "Trajectories are generated according to 3 mobiltiy profiles:cars, walk, bike\n",
    "    * Source and destination taken from the augmented medoids\n",
    "    * Gps interpolation\n",
    "    * Time delta interpolation\n",
    "3. Build the GeoLife augmented data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports cell\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import osmnx as ox \n",
    "from sklearn.neighbors import KDTree\n",
    "import networkx as nx\n",
    "import folium\n",
    "import random\n",
    "from geographiclib.geodesic import Geodesic\n",
    "import math\n",
    "import yaml\n",
    "import skmob\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "\n",
    "with open(\"conf.yaml\") as f:\n",
    "    conf = yaml.load(f, Loader = yaml.FullLoader)\n",
    "\n",
    "#base_path = conf[\"base_path\"]\n",
    "out_path = conf[\"out_path\"]\n",
    "interpolation_distance = conf[\"interpolation_distance\"]\n",
    "n_trajectory_user = conf[\"n_trajectory_user\"]\n",
    "num_cars = conf[\"n_cars\"]\n",
    "num_bikes = conf[\"n_bikes\"]\n",
    "num_pedestrians = conf[\"n_pedestrians\"]\n",
    "geolife_data_path = conf[\"geolife_data_path\"]\n",
    "start_time = conf[\"start_time\"]\n",
    "end_time = conf[\"end_time\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in order to load the augmented medoids (medoids + random locations) only once\n",
    "medoids = pd.read_csv(out_path + \"geolife_augmented_medoids.csv\", usecols = [\"lat\", \"lon\"])\n",
    "print(medoids.head())\n",
    "\n",
    "n_medoids = len(medoids)\n",
    "print(\"We have a total of {:d} starting/arrival points\".format(n_medoids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Geo_life maps: drive, bike, walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#get graphs from place and serialize them on disk\n",
    "\n",
    "#get the graphs\n",
    "D = ox.graph_from_place('Beijing, China', which_result=2, network_type='drive')\n",
    "B = ox.graph_from_place('Beijing, China', which_result=2, network_type='bike')\n",
    "W = ox.graph_from_place('Beijing, China', which_result=2, network_type='walk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serialize them on disk\n",
    "ox.save_graphml(D, out_path+\"drive_graph.graphml\")\n",
    "ox.save_graphml(B, out_path+\"bike_graph.graphml\")\n",
    "ox.save_graphml(W, out_path+\"walk_graph.graphml\")\n",
    "\n",
    "print(\"Serialized graphs on disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load graphs from files if already downloaded\n",
    "\n",
    "D = ox.load_graphml(out_path+\"drive_graph.graphml\")\n",
    "B = ox.load_graphml(out_path+\"bike_graph.graphml\")\n",
    "W = ox.load_graphml(out_path+\"walk_graph.graphml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trajectory generation\n",
    "We use the put_datetime helper function in order to put datetimes in the generated trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def str_time_prop(start, end, format, prop):\n",
    "    \"\"\"Get a time at a proportion of a range of two formatted times.\n",
    "\n",
    "    start and end should be strings specifying times formated in the\n",
    "    given format (strftime-style), giving an interval [start, end].\n",
    "    prop specifies how a proportion of the interval to be taken after\n",
    "    start.  The returned time will be in the specified format.\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.mktime(time.strptime(start, format))\n",
    "    etime = time.mktime(time.strptime(end, format))\n",
    "\n",
    "    ptime = stime + prop * (etime - stime)\n",
    "\n",
    "    return time.strftime(format, time.localtime(ptime))\n",
    "\n",
    "\n",
    "def random_date(start, end, prop):\n",
    "    return str_time_prop(start, end, '%Y-%m-%d %H:%M:%S', prop)\n",
    "\n",
    "#print(random_date(\"2008-06-01 00:00:00\", \"2008-08-31 23:59:00\", random.random()))\n",
    "\n",
    "def put_datetime(trajs_df, speed):\n",
    "    \n",
    "    import datetime\n",
    "    from datetime import timedelta\n",
    "\n",
    "\n",
    "    traj_copy = trajs_df.copy(deep = True)\n",
    "    traj_copy[\"date_time\"] = start_time\n",
    "\n",
    "    #selecting each traj by uid and tid\n",
    "    \n",
    "    overlaps = 0\n",
    "    index = 0\n",
    "    \n",
    "    for uid in range(traj_copy.uid.min(), traj_copy.uid.max() + 1):\n",
    "        # trajectories for user uid\n",
    "        user = traj_copy[traj_copy[\"uid\"] == uid]\n",
    "        \n",
    "        #reset intervals\n",
    "        intervals = []\n",
    "        \n",
    "        tid = user.tid.min()\n",
    "        max_tid = user.tid.max()\n",
    "        \n",
    "        while (tid <= max_tid):\n",
    "            \n",
    "            initial_tid_index = index\n",
    "\n",
    "            #get a random date in our range\n",
    "            date = random_date(start_time, end_time, random.random())\n",
    "            date_time_obj = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            #print(\"Trajectory {:d} starting at {:s}\".format(tid, date))\n",
    "            traj = user[user[\"tid\"] == tid]\n",
    "            #put the starting date at the beginning of the traj\n",
    "            traj_copy.iat[index, 4] = date\n",
    "            t_since_start = 0\n",
    "            d_tot = 0\n",
    "            #in order to do it only once\n",
    "            t_len = len(traj)\n",
    "\n",
    "            for i in range(1, t_len):\n",
    "                try : \n",
    "                    #print(traj.iloc[i])\n",
    "                    dist = geodesic((traj.iloc[i-1].lat, traj.iloc[i].lon), \\\n",
    "                                               (traj.iloc[i].lat, traj.iloc[i].lon))\n",
    "\n",
    "                    d_tot += dist.meters\n",
    "\n",
    "                    #gets m / m/s\n",
    "                    tdelta = (dist.meters)/speed\n",
    "                    t_since_start += tdelta\n",
    "\n",
    "                    row_dt = date_time_obj + timedelta(seconds = t_since_start)\n",
    "                    index += 1\n",
    "                    traj_copy.iat[index, 4] =  row_dt\n",
    "\n",
    "                except IndexError:\n",
    "                    print(i)\n",
    "                    #print(traj.iloc[i-1])\n",
    "                    #print(traj.iloc[i])\n",
    "            try:        \n",
    "                n_interval = pd.Interval(date_time_obj.timestamp(), row_dt.timestamp())\n",
    "            except:\n",
    "                print(\"Error interval:\",date_time_obj.timestamp(), row_dt.timestamp())\n",
    "                n_interval = pd.Interval(row_dt.timestamp(), date_time_obj.timestamp())\n",
    "                \n",
    "            #check if the trajectory is time-overlapping with another one\n",
    "            overlapping = False #stupid flag\n",
    "            for interval in intervals:\n",
    "                if (interval.overlaps(n_interval)):\n",
    "                    overlapping = True\n",
    "                    overlaps += 1\n",
    "                    break\n",
    "                    \n",
    "            if (overlapping):\n",
    "                index = initial_tid_index\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                intervals.append(n_interval) \n",
    "                tid += 1\n",
    "                index += 1\n",
    "                \n",
    "            #print(\"Total time for traj n {:d}: {:f} minutes. meters: {:f}\".format(tid, t_since_start/60, d_tot))\n",
    "            #print(traj.iloc[0].date_time)\n",
    "            #print(traj.iloc[i].date_time)\n",
    "\n",
    "            #print(traj)\n",
    "    print(\"Put datetimes on {:d} rows, generated {:d} overlapping trajectories\".format(index - 1, overlaps))\n",
    "    return traj_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We define the interpolation and the faker functions to be called for each generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolates the dataframe\n",
    "def interpolator(gdf, uid):\n",
    "    \n",
    "    cols = [\"lat\", \"lon\", \"uid\", \"tid\"]\n",
    "    #traj_df = pd.DataFrame(columns = cols)\n",
    "    rows = []\n",
    "    \n",
    "    #meters for interpolation\n",
    "    k = interpolation_distance\n",
    "    geod = Geodesic.WGS84\n",
    "\n",
    "    for i in range(len(gdf) - 1):\n",
    "\n",
    "        l = geod.InverseLine(gdf.iloc[i].y, gdf.iloc[i].x, gdf.iloc[i+1].y, gdf.iloc[i+1].x)\n",
    "        # number of gps points between source and destination, given the interpolation_distance\n",
    "        ds = k; n = int(math.ceil(l.s13 / ds))\n",
    "        for i in range(n + 1):\n",
    "            #if i == 0:\n",
    "                #print( \"distance latitude longitude azimuth\")\n",
    "            s = min(ds * i, l.s13)\n",
    "            g = l.Position(s, Geodesic.STANDARD | Geodesic.LONG_UNROLL)\n",
    "            lat = g[\"lat2\"]\n",
    "            lon = g[\"lon2\"]\n",
    "            \n",
    "            new_row = [lat, lon, uid, 0]\n",
    "            rows.append(new_row)\n",
    "            #print(traj_df.head())\n",
    "    \n",
    "    traj_df = pd.DataFrame(rows, columns = cols)\n",
    "    \n",
    "    return traj_df\n",
    "    \n",
    "\n",
    "#faker function\n",
    "def faker(profile, n_users):\n",
    "    #traj faker helper fun\n",
    " \n",
    "    print(\"Generating {:d} trajectories for {:d} users\".format(n_trajectory_user,n_users))\n",
    "    if(n_users <=0):\n",
    "        print(\"No trjectories for: \",profile)\n",
    "        return\n",
    "    cols = [\"lat\", \"lon\", \"uid\", \"tid\"]\n",
    "    fake_trajs = pd.DataFrame(columns = cols)\n",
    "    #uid to recognize different types of fake users\n",
    "    fake_uid = 0\n",
    "    speed = 0\n",
    "    \n",
    "    if (profile == \"drive\"):\n",
    "        G = ox.load_graphml(out_path+\"drive_graph.graphml\")\n",
    "        # starting uid for drive users\n",
    "        fake_uid = 1000\n",
    "        speed = 11.1\n",
    "        \n",
    "    elif (profile == \"bike\"):\n",
    "        G = ox.load_graphml(out_path+\"bike_graph.graphml\")\n",
    "        fake_uid = 2000\n",
    "        speed = 4.3\n",
    "\n",
    "    elif (profile == \"walk\"):\n",
    "        G = ox.load_graphml(out_path+\"walk_graph.graphml\")\n",
    "        fake_uid = 3000\n",
    "        speed = 1.38\n",
    "\n",
    "    else:\n",
    "        print(\"not a valid profile!\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Loaded {:s} graph from disk\".format(profile))\n",
    "    \n",
    "    \n",
    "    gdf_nodes, gdf_edges = ox.graph_to_gdfs(G)\n",
    "    #print(gdf_nodes)\n",
    "    # build the tree\n",
    "    tree = KDTree(gdf_nodes[['y', 'x']], metric='euclidean')\n",
    "    n_trajs = 0\n",
    "    errs = 0\n",
    "    trajs = []\n",
    "    # users\n",
    "    for i in range(0, n_users):\n",
    "        # trajectories for every user\n",
    "        for j in range(0, n_trajectory_user):\n",
    "\n",
    "            #sample 2 indexes\n",
    "            # Select random the source and destination among all the locations\n",
    "            picks = random.sample(range(0, n_medoids), 2)\n",
    "            # Source\n",
    "            med_a = picks[0]\n",
    "            #destination\n",
    "            med_b = picks[1]\n",
    "\n",
    "            #get lat and lng for medoids\n",
    "            med_a = (medoids.iloc[med_a].lat, medoids.iloc[med_a].lon)\n",
    "            med_b = (medoids.iloc[med_b].lat, medoids.iloc[med_b].lon)\n",
    "\n",
    "            #get the nearest points in the gdf\n",
    "            med_a_idx = tree.query([med_a], k=1, return_distance=False)[0]\n",
    "            med_b_idx = tree.query([med_b], k=1, return_distance=False)[0]\n",
    "\n",
    "            closest_node_to_a = gdf_nodes.iloc[med_a_idx].index.values[0]\n",
    "            closest_node_to_b = gdf_nodes.iloc[med_b_idx].index.values[0]  \n",
    "\n",
    "            #calculate the shortest path\n",
    "            try:\n",
    "                path = nx.shortest_path(G, \n",
    "                             closest_node_to_a,\n",
    "                             closest_node_to_b,\n",
    "                             weight='length')\n",
    "                n_trajs += 1\n",
    "\n",
    "            #happens when there's not path between two points    \n",
    "            except nx.NetworkXNoPath:\n",
    "                errs += 1\n",
    "                \n",
    "                \n",
    "            #print(path)\n",
    "            gdf = gdf_nodes.loc[path]\n",
    "            #print(\"Gdf number {:d}\".format(n_trajs))\n",
    "            #print(gdf.head())\n",
    "\n",
    "            traj = interpolator(gdf, fake_uid)\n",
    "            # add the interpolated gps points\n",
    "            traj[\"tid\"] = n_trajs\n",
    "            \n",
    "            trajs.append(traj)\n",
    "            #fake_trajs = fake_trajs.append(traj, ignore_index = True)\n",
    "            \n",
    "            \n",
    "            #print route for checking purposes\n",
    "            \"\"\"fig, ax = ox.plot_graph_route(G, path, fig_height=10, \n",
    "                                  fig_width=10, \n",
    "                                  show=False, close=False, \n",
    "                                  edge_color='black',\n",
    "                                  orig_dest_node_color='green',\n",
    "                                  route_color='green')\n",
    "            plt.show()\"\"\"\n",
    "            \n",
    "        #on to another user!\n",
    "        fake_uid += 1\n",
    "\n",
    "    fake_trajs = pd.concat(trajs, ignore_index = True)\n",
    "    fake_trajs.to_csv(out_path+\"tmp_fake_traj.csv\")\n",
    "    print(\"generated {:d} trajectories for {:d} users with a {:s} profile. {:d} errors generated\"\n",
    "          .format(n_trajs, n_users, profile, errs))\n",
    "    \n",
    "    #print(fake_trajs.head())\n",
    "    \n",
    "    print(\"now putting datetimes on generated trajectories\")\n",
    "    return put_datetime(fake_trajs, speed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test our faker function with a relatively small generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_trajectory_user = 1\n",
    "interpolation_distance = 10\n",
    "test = faker(\"walk\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Now starting generation with {:d} cars, {:d} bikes and {:d} pedestrians\"\n",
    "     .format(num_cars, num_bikes, num_pedestrians))\n",
    "\n",
    "cars = faker(\"drive\", num_cars)\n",
    "bikes = faker(\"bike\", num_bikes)\n",
    "pedestrians = faker(\"walk\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#cars.to_csv(out_path+\"augmented_cars.csv\")\n",
    "#bikes.to_csv(out_path+\"augmented_bikes.csv\")\n",
    "pedestrians.to_csv(out_path+\"geolife_augmented_pedestrians.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrians.loc[pedestrians[\"uid\"] == 3001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the trajectory generation worked correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skmob\n",
    "\n",
    "#print(trajs)\n",
    "\n",
    "tdf = skmob.TrajDataFrame(trajs[(trajs[\"uid\"] == 1000)], longitude = \"lon\", datetime = \"date_time\")\n",
    "print(tdf)\n",
    "\n",
    "\n",
    "tdf.plot_trajectory(zoom=12, weight=3, opacity=0.9, tiles='Stamen Toner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the GeoLife augmented data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod the original Geolife\n",
    "col_names = [\"lat\", \"lon\", \"uid\", \"tid\", \"date_time\"] \n",
    "\n",
    "# Uncommment if needed\n",
    "#pedestrians = pd.read_csv(out_path + \"augmented_pedestrians.csv\", parse_dates = True, infer_datetime_format = True,index_col = 0)\n",
    "#bikes = pd.read_csv(data_path + \"augmented_bikes.csv\", parse_dates = True, infer_datetime_format = True,index_col = 0)\n",
    "#cars = pd.read_csv(data_path + \"augmented_cars.csv\", parse_dates = True, infer_datetime_format = True,index_col = 0)\n",
    "\n",
    "cols = [\"date_time\", \"lat\", \"lon\", \"tid\", \"uid\"]\n",
    "\n",
    "df = pd.read_csv(geolife_data_path + \"geo_life_full.csv\", \\\n",
    "                 usecols = cols, parse_dates = True, infer_datetime_format = True)\n",
    "\n",
    "pedestrians[\"tid\"] += df.tid.max()\n",
    "augmented = pd.concat([pedestrians, df], axis=0, ignore_index=True)\n",
    "augmented.to_csv(out_path + \"geolife_full_augmented.csv\")\n",
    "\n",
    "\n",
    "#restricting to beijing area\n",
    "#df = df[(df['lat'].between(39.54, 40.3)) & (df['lon'].between(115.75, 117.13))]\n",
    "\n",
    "#restricting to june - august 2008\n",
    "#start_time = \"2008-06-01 00:00:00\"\n",
    "#end_time = \"2008-08-31 23:59:00\"\n",
    "\n",
    "#original = (df[(df.date_time > start_time) & (df.date_time < end_time)]).copy()\n",
    "\n",
    "#print(original.head())\n",
    "#print(original.tid.max())\n",
    "\n",
    "#augmented[\"date_time\"] = pd.to_datetime(augmented[\"date_time\"], format = \"%Y-%m-%d %H:%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrians[\"tid\"] += original.tid.max()\n",
    "#bikes[\"tid\"] += (original.tid.max() + pedestrians.tid.max())\n",
    "#cars[\"tid\"] += (original.tid.max() + pedestrians.tid.max() + bikes.tid.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmented = pd.concat([pedestrians, bikes, cars, original], axis=0, ignore_index=True)\n",
    "augmented = pd.concat([pedestrians, original], axis=0, ignore_index=True)\n",
    "augmented.to_csv(out_path + \"geolife_full_augmented.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary analysis of the GeoLife augmented data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skmob\n",
    "augmented = pd.read_csv(out_path + \"geolife_full_augmented.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(augmented[augmented[\"uid\"] >= 3000][\"uid\"].unique())\n",
    "augmented.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = skmob.TrajDataFrame(augmented, latitude=\"lat\", longitude=\"lon\", datetime=\"date_time\",user_id=\"uid\",trajectory_id=\"tid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check trajectories of pedestrian (uid>=3000) and plot the trajectories\n",
    "tdf_sele = tdf[tdf[\"uid\"]>3000]\n",
    "tdf_sele[\"tid\"].unique()[:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tdf_sele[tdf_sele[\"tid\"] == 55948]\n",
    "m = s.plot_trajectory(zoom=12, weight=3, opacity=0.9, tiles='Stamen Toner')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flows\n",
    "from skmob.tessellation import tilers\n",
    "tessellation = tilers.tiler.get(\"squared\", base_shape=\"Beijing, China\", meters=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = tdf_sele.to_flowdataframe(tessellation=tessellation, self_loops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = fdf.plot_flows(flow_color='red',flow_weight=10)\n",
    "fdf.plot_tessellation(popup_features=['tile_ID', 'population'],map_osm=m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
