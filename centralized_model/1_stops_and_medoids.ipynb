{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Place Detection based on GeoLife\n",
    "1. Detect and cluster the stop places \n",
    "2. calculate  cluster's medoids\n",
    "3. extend the medoids with extra aggregation points, these represent the origins and destinatins of the synthetic trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "import skmob\n",
    "from skmob.preprocessing import detection\n",
    "from skmob.preprocessing import filtering\n",
    "import folium\n",
    "import sklearn\n",
    "import numpy\n",
    "from skmob.preprocessing import clustering\n",
    "\n",
    "\n",
    "\n",
    "with open(\"conf.yaml\") as f:\n",
    "    conf = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "out_path = conf[\"out_path\"]\n",
    "data_path = conf[\"data_path\"]\n",
    "geolife_data_path = conf[\"geolife_data_path\"]\n",
    "\n",
    "stop_radius_factor = conf[\"stop_radius_factor\"]\n",
    "minutes_for_a_stop = conf[\"minutes_for_a_stop\"]\n",
    "spatial_radius_km = conf[\"spatial_radius_km\"]\n",
    "\n",
    "start_time = conf[\"start_time\"]\n",
    "end_time = conf[\"end_time\"]\n",
    "extended_medoids = conf[\"extended_medoids\"]\n",
    "\n",
    "beijing_lat_min = conf[\"beijing_lat_min\"]\n",
    "beijing_lat_max = conf[\"beijing_lat_max\"]\n",
    "beijing_lon_min = conf[\"beijing_lon_min\"]\n",
    "beijing_lon_max = conf[\"beijing_lon_max\"]\n",
    "\n",
    "min_cluster_stop_sample = conf[\"min_cluster_stop_sample\"]\n",
    "cluster_radius_km = conf[\"cluster_radius_km\"]\n",
    "speed_filter = conf[\"speed_filter\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and filter\n",
    "cols = [\"date_time\", \"lat\", \"lon\", \"uid\",\"tid\"]\n",
    "df = pd.read_csv(os.path.join(geolife_data_path,\"geo_life_full.csv\"),usecols = cols, parse_dates = [\"date_time\"])\n",
    "\n",
    "#restricting to beijing area\n",
    "df = df[(df['lat'].between(beijing_lat_min, beijing_lat_max )) & (df['lon'].between(beijing_lon_min, beijing_lon_max))]\n",
    "\n",
    "#restricting to period of interest\n",
    "df = df[(df.date_time > start_time) & (df.date_time < end_time)]\n",
    "\n",
    "#build trajectories\n",
    "tdf = skmob.TrajDataFrame(df, latitude='lat', longitude='lon', datetime='date_time', user_id='uid',trajectory_id =\"tid\")\n",
    "\n",
    "#filter noise from trajectories\n",
    "ftdf = filtering.filter(tdf, max_speed_kmh=speed_filter)\n",
    "ftdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Stop Places and clustering\n",
    "Convert to TrajectoryDataFrame and set the uid column to \"0\" in order to calculate and cluster stops for all the trajectories, indipendently on the user who recorded each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detecting stops\n",
    "stdf = detection.stops(tdf, stop_radius_factor=stop_radius_factor, minutes_for_a_stop=minutes_for_a_stop, spatial_radius_km=spatial_radius_km, leaving_time=True)\n",
    "stdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we show the stopping points on a folium map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping_points = folium.Map(location=[39.9042, 116.4074], tiles=\"Stamen Toner\")\n",
    "\n",
    "stdf.plot_stops(stopping_points)\n",
    "stopping_points.save(out_path+\"geolife_stop_places.html\")\n",
    "\n",
    "# show the map here\n",
    "#stopping_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering the stopping points\n",
    "\n",
    "clustered_stops = folium.Map(location=[39.9042, 116.4074], tiles=\"Stamen Toner\")\n",
    "cstdf = clustering.cluster(stdf, cluster_radius_km=cluster_radius_km)\n",
    "\n",
    "#printing on a folium map\n",
    "cstdf.plot_stops(clustered_stops,max_users = 200)\n",
    "clustered_stops.save(out_path+\"geolife_clustered_stop_places.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_i = cstdf[(cstdf[\"cluster\"] == 2)].copy()\n",
    "cluster_i.reset_index(inplace=True)\n",
    "pairwise = sklearn.metrics.pairwise_distances(cluster_i[[\"lat\", \"lng\"]], metric='euclidean')\n",
    "pairwise.shape\n",
    "# index of vector pairwise with the smallest distance\n",
    "medoid = numpy.argmin(pairwise.sum(axis=0))\n",
    "cluster_i.loc[[medoid]]\n",
    "#print(medoid)\n",
    "#medoids.append(cluster_i.loc[[medoid]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute the medoids\n",
    "Now we calculate the medoid for each cluster and we put each of them in a dataframe, then we serialize it on disk for further usage.\n",
    "Medoid is obtained by finding the point of the cluster with minimum diastance from any other point of the same cluster\n",
    "- pariwise distances among all the cluster's points\n",
    "- sum the distances by row\n",
    "- find the lowest  aggregated distance\n",
    "\n",
    "[Medoid on Stack over flow](https://stackoverflow.com/questions/38017194/calculating-medoid-of-a-cluster-python)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medoids = pd.DataFrame()\n",
    "\n",
    "#for each cluster\n",
    "#for i in range(0, cstdf.cluster.max() + 1):\n",
    "for cluster_id in cstdf.cluster.unique():\n",
    "    cluster_i = cstdf[(cstdf[\"cluster\"] == cluster_id)].copy()\n",
    "    cluster_i.reset_index(inplace=True)\n",
    "    pairwise = sklearn.metrics.pairwise_distances(cluster_i[[\"lat\", \"lng\"]], metric='euclidean')\n",
    "    # index of vector pairwise with the smallest distance\n",
    "    medoid = numpy.argmin(pairwise.sum(axis=0))\n",
    "    #print(cluster_i.loc[medoid])\n",
    "    medoids = medoids.append(cluster_i.loc[[medoid]])\n",
    "\n",
    "#setting back the index\n",
    "medoids = medoids.set_index(\"index\")\n",
    "medoids.to_csv(out_path+\"geolife_medoids.csv\")\n",
    "\n",
    "map_locations = folium.Map(location=[39.9042, 116.4074], tiles=\"Stamen Toner\")\n",
    "#we plot the medoids on a folium map\n",
    "#medoids.plot_stops(map_locations)\n",
    "\n",
    "for medoid in medoids.iterrows():\n",
    "    long = medoid[1][\"lng\"]\n",
    "    lat = medoid[1][\"lat\"]\n",
    "    pop = medoid[1][\"cluster\"]\n",
    "    folium.Marker((lat,long),popup=\"cluster:\"+str(pop)).add_to(map_locations)\n",
    "    \n",
    "\n",
    "cstdf.plot_stops(map_locations,max_users=200)\n",
    "\n",
    "map_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extend the locations with extra locations \n",
    "In order to get more trajectories in the broader Beijing area, we try to pick random points to \"augment\" our medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "\n",
    "#picking 100 random points in our inner bounding box perimeter\n",
    "rd_pts = [(rand.uniform(beijing_lat_min, beijing_lat_max), (rand.uniform(beijing_lon_min, beijing_lon_max))) for i in range(extended_medoids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize medoids AND random points on a folium map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium \n",
    "\n",
    "for pt in rd_pts:\n",
    "    folium.Marker(pt).add_to(map_locations)\n",
    "\n",
    "#map_locations.save(out_path+\"geolife_augmented_medoids.html\")\n",
    "map_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df = pd.DataFrame(rd_pts, columns = [\"lat\", \"lon\"])\n",
    "print(points_df.head())\n",
    "\n",
    "meds_reset = medoids.reset_index().drop([\"index\", \"datetime\", \"leaving_datetime\", \"uid\", \"cluster\"], axis = 1)\n",
    "meds_reset = meds_reset.rename(columns = {\"lng\":\"lon\"})\n",
    "augmented_medoids = pd.concat([points_df, meds_reset], ignore_index = True)\n",
    "augmented_medoids.to_csv(os.path.join(out_path,\"geolife_augmented_medoids.csv\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
